global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'codelab-monitor'

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'otel-collector'
    static_configs:
      - targets: ['otel-collector:8888']

  # Remove or comment out this duplicate job
  # - job_name: 'otel-collector'
  #   static_configs:
  #     - targets: ['otel-collector:8888']

  - job_name: 'dapr'
    scrape_interval: 5s
    static_configs:
      - targets: ['audit-service:9093', 'airflow-trigger-service:9097', 'airflow-config-service:9101', 'management-service:9105', 'pythonapp:9094', 'lineage-service:9109']  # Updated to use the correct hostnames and ports

  # - job_name: 'apps'
  #   scrape_interval: 5s
  #   static_configs:
  #     - targets: ['audit-service:9091', 'airflow-trigger-service:9095', 'airflow-config-service:9099', 'management-service:9103', 'pythonapp:9092', 'lineage-service:9107']  # Separate job for app metrics